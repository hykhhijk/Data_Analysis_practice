{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e645fed",
   "metadata": {
    "papermill": {
     "duration": 0.013553,
     "end_time": "2022-03-30T13:31:43.996765",
     "exception": false,
     "start_time": "2022-03-30T13:31:43.983212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Baseline for Ubiquant Market Prediction using ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df32325",
   "metadata": {
    "papermill": {
     "duration": 0.015503,
     "end_time": "2022-03-30T13:31:44.032652",
     "exception": false,
     "start_time": "2022-03-30T13:31:44.017149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Thanks to notebook contributors for make baseline for my notebook**\n",
    "- https://www.kaggle.com/code/sohier/competition-api-detailed-introduction/notebook\n",
    "- https://www.kaggle.com/code/pythonash/end-to-end-simple-and-powerful-dnn-with-leakyrelu\n",
    "- https://www.kaggle.com/code/robikscube/fast-data-loading-and-low-mem-with-parquet-files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986c84d1",
   "metadata": {
    "papermill": {
     "duration": 0.009485,
     "end_time": "2022-03-30T13:31:44.051944",
     "exception": false,
     "start_time": "2022-03-30T13:31:44.042459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First import libraries and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cd37d25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T04:58:01.077998Z",
     "start_time": "2022-04-07T04:58:01.072987Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-30T13:31:44.081556Z",
     "iopub.status.busy": "2022-03-30T13:31:44.080942Z",
     "iopub.status.idle": "2022-03-30T13:31:51.961638Z",
     "shell.execute_reply": "2022-03-30T13:31:51.960466Z",
     "shell.execute_reply.started": "2022-03-30T12:46:06.43505Z"
    },
    "papermill": {
     "duration": 7.900134,
     "end_time": "2022-03-30T13:31:51.961783",
     "exception": false,
     "start_time": "2022-03-30T13:31:44.061649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d993ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T04:32:07.037184Z",
     "start_time": "2022-04-07T04:31:31.285799Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-30T13:31:51.987891Z",
     "iopub.status.busy": "2022-03-30T13:31:51.987095Z",
     "iopub.status.idle": "2022-03-30T13:32:31.312242Z",
     "shell.execute_reply": "2022-03-30T13:32:31.311320Z",
     "shell.execute_reply.started": "2022-03-30T12:23:42.620177Z"
    },
    "papermill": {
     "duration": 39.340095,
     "end_time": "2022-03-30T13:32:31.312397",
     "exception": false,
     "start_time": "2022-03-30T13:31:51.972302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('D:/kaggle_datasets/ubiquant-parquet/train_low_mem.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d91f320",
   "metadata": {
    "papermill": {
     "duration": 0.009666,
     "end_time": "2022-03-30T13:32:31.332587",
     "exception": false,
     "start_time": "2022-03-30T13:32:31.322921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess dataset\n",
    "\n",
    "Because of it's baseline I use only f_n for features for X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c72961c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T16:02:21.237521Z",
     "start_time": "2022-04-05T16:02:16.358551Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-30T13:32:34.337172Z",
     "iopub.status.busy": "2022-03-30T13:32:34.321467Z",
     "iopub.status.idle": "2022-03-30T13:32:41.679382Z",
     "shell.execute_reply": "2022-03-30T13:32:41.678908Z",
     "shell.execute_reply.started": "2022-03-30T12:24:10.683925Z"
    },
    "papermill": {
     "duration": 10.336824,
     "end_time": "2022-03-30T13:32:41.679509",
     "exception": false,
     "start_time": "2022-03-30T13:32:31.342685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_col = df.drop([\"row_id\", \"time_id\", \"investment_id\", \"target\"], axis=1).columns\n",
    "X_train = df[index_col]\n",
    "X_train = X_train.astype(\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c9c5f6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T16:02:22.274391Z",
     "start_time": "2022-04-05T16:02:22.259742Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-30T13:32:41.704460Z",
     "iopub.status.busy": "2022-03-30T13:32:41.703344Z",
     "iopub.status.idle": "2022-03-30T13:32:41.705179Z",
     "shell.execute_reply": "2022-03-30T13:32:41.705565Z"
    },
    "papermill": {
     "duration": 0.016035,
     "end_time": "2022-03-30T13:32:41.705694",
     "exception": false,
     "start_time": "2022-03-30T13:32:41.689659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a8ada0",
   "metadata": {
    "papermill": {
     "duration": 0.011464,
     "end_time": "2022-03-30T13:32:41.727097",
     "exception": false,
     "start_time": "2022-03-30T13:32:41.715633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Making model\n",
    "\n",
    "I make simple model using Dense layer and BatchNormalizaion without hyper parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba65d498",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T05:08:41.672759Z",
     "start_time": "2022-04-07T05:08:40.435698Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-30T13:32:41.753747Z",
     "iopub.status.busy": "2022-03-30T13:32:41.753248Z",
     "iopub.status.idle": "2022-03-30T13:32:45.722742Z",
     "shell.execute_reply": "2022-03-30T13:32:45.723351Z"
    },
    "papermill": {
     "duration": 3.986594,
     "end_time": "2022-03-30T13:32:45.723539",
     "exception": false,
     "start_time": "2022-03-30T13:32:41.736945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Input = keras.layers.Input(shape=X_train.shape[1])\n",
    "x = keras.layers.Dense(128, activation=\"relu\")(Input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(16, activation=\"relu\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "Output = keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "model = keras.models.Model(inputs = Input, outputs = Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ff81b20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:47:42.911304Z",
     "start_time": "2022-04-05T14:15:02.950598Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-30T13:32:45.751718Z",
     "iopub.status.busy": "2022-03-30T13:32:45.750965Z",
     "iopub.status.idle": "2022-03-30T14:05:48.148745Z",
     "shell.execute_reply": "2022-03-30T14:05:48.148314Z"
    },
    "papermill": {
     "duration": 1982.413617,
     "end_time": "2022-03-30T14:05:48.148882",
     "exception": false,
     "start_time": "2022-03-30T13:32:45.735265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2513128 samples, validate on 628282 samples\n",
      "Epoch 1/5\n",
      "2513128/2513128 [==============================] - 357s 142us/sample - loss: 0.8404 - mse: 0.8404 - val_loss: 0.8095 - val_mse: 0.8095\n",
      "Epoch 2/5\n",
      "2513128/2513128 [==============================] - 364s 145us/sample - loss: 0.8333 - mse: 0.8333 - val_loss: 0.8134 - val_mse: 0.8134\n",
      "Epoch 3/5\n",
      "2513128/2513128 [==============================] - 374s 149us/sample - loss: 0.8303 - mse: 0.8303 - val_loss: 0.8103 - val_mse: 0.8103\n",
      "Epoch 4/5\n",
      "2513128/2513128 [==============================] - 445s 177us/sample - loss: 0.8283 - mse: 0.8283 - val_loss: 0.8175 - val_mse: 0.8175\n",
      "Epoch 5/5\n",
      "2513128/2513128 [==============================] - 418s 166us/sample - loss: 0.8264 - mse: 0.8264 - val_loss: 0.8800 - val_mse: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fa00604198>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b86a1cd",
   "metadata": {},
   "source": [
    "# 특성 공학 및 하이퍼 파라미터 서칭 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b45bce74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:39:34.671084Z",
     "start_time": "2022-04-07T06:39:34.480488Z"
    }
   },
   "outputs": [],
   "source": [
    "Input = keras.layers.Input(shape=X_train.shape[1])\n",
    "x = keras.layers.Dense(128)(Input)\n",
    "x = keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(64)(x)\n",
    "x = keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(32)(x)\n",
    "x = keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(16)(x)\n",
    "x = keras.layers.LeakyReLU(alpha=0.2, )(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "Output = keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "model_leak = keras.models.Model(inputs = Input, outputs = Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f4f3ce2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T15:23:30.602843Z",
     "start_time": "2022-04-05T14:49:56.176370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2513128 samples, validate on 628282 samples\n",
      "Epoch 1/5\n",
      "2513128/2513128 [==============================] - 469s 187us/sample - loss: 0.8408 - mse: 0.8408 - val_loss: 0.8120 - val_mse: 0.8120\n",
      "Epoch 2/5\n",
      "2513128/2513128 [==============================] - 421s 167us/sample - loss: 0.8347 - mse: 0.8347 - val_loss: 0.8096 - val_mse: 0.8096\n",
      "Epoch 3/5\n",
      "2513128/2513128 [==============================] - 427s 170us/sample - loss: 0.8323 - mse: 0.8323 - val_loss: 0.8087 - val_mse: 0.8087\n",
      "Epoch 4/5\n",
      "2513128/2513128 [==============================] - 347s 138us/sample - loss: 0.8308 - mse: 0.8308 - val_loss: 0.8127 - val_mse: 0.8127\n",
      "Epoch 5/5\n",
      "2513128/2513128 [==============================] - 347s 138us/sample - loss: 0.8296 - mse: 0.8296 - val_loss: 0.8107 - val_mse: 0.8107\n"
     ]
    }
   ],
   "source": [
    "model_leak.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "history = model_leak.fit(X_train, y_train, validation_split=0.2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "17f4efd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:42:31.864654Z",
     "start_time": "2022-04-07T06:39:39.352032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 251312 samples, validate on 62829 samples\n",
      "Epoch 1/5\n",
      "251312/251312 [==============================] - 34s 136us/sample - loss: 0.8509 - mse: 0.8509 - val_loss: 0.8379 - val_mse: 0.8379\n",
      "Epoch 2/5\n",
      "251312/251312 [==============================] - 33s 133us/sample - loss: 0.8359 - mse: 0.8359 - val_loss: 0.8348 - val_mse: 0.8348\n",
      "Epoch 3/5\n",
      "251312/251312 [==============================] - 35s 139us/sample - loss: 0.8329 - mse: 0.8329 - val_loss: 0.8351 - val_mse: 0.8351\n",
      "Epoch 4/5\n",
      "251312/251312 [==============================] - 35s 138us/sample - loss: 0.8304 - mse: 0.8304 - val_loss: 0.8383 - val_mse: 0.8383\n",
      "Epoch 5/5\n",
      "251312/251312 [==============================] - 35s 140us/sample - loss: 0.8287 - mse: 0.8287 - val_loss: 0.8276 - val_mse: 0.8276\n"
     ]
    }
   ],
   "source": [
    "model_leak.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "history = model_leak.fit(X_train, y_train, validation_split=0.2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "739a67d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T16:04:17.979487Z",
     "start_time": "2022-04-05T16:04:07.753791Z"
    }
   },
   "outputs": [],
   "source": [
    "X_valid, X_train, y_valid, y_train = train_test_split(X_train, y_train, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "505d403d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T16:15:37.553637Z",
     "start_time": "2022-04-05T16:12:50.050545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 251312 samples, validate on 62829 samples\n",
      "Epoch 1/5\n",
      "251312/251312 [==============================] - 34s 137us/sample - loss: 0.8169 - mse: 0.8169 - val_loss: 0.8371 - val_mse: 0.8371\n",
      "Epoch 2/5\n",
      "251312/251312 [==============================] - 33s 133us/sample - loss: 0.8115 - mse: 0.8115 - val_loss: 0.8415 - val_mse: 0.8415\n",
      "Epoch 3/5\n",
      "251312/251312 [==============================] - 34s 134us/sample - loss: 0.8080 - mse: 0.8080 - val_loss: 0.8432 - val_mse: 0.8432\n",
      "Epoch 4/5\n",
      "251312/251312 [==============================] - 33s 130us/sample - loss: 0.8042 - mse: 0.8042 - val_loss: 0.8465 - val_mse: 0.8465\n",
      "Epoch 5/5\n",
      "251312/251312 [==============================] - 33s 132us/sample - loss: 0.7990 - mse: 0.7990 - val_loss: 0.8469 - val_mse: 0.8469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x208414a10b8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(learning_rate=0.0003), metrics=[\"mse\"])\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df0a4273",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T16:21:13.489937Z",
     "start_time": "2022-04-06T16:17:55.554382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 251312 samples, validate on 62829 samples\n",
      "Epoch 1/5\n",
      "251312/251312 [==============================] - 40s 159us/sample - loss: 0.8186 - mse: 0.8186 - val_loss: 0.8346 - val_mse: 0.8346\n",
      "Epoch 2/5\n",
      "251312/251312 [==============================] - 40s 159us/sample - loss: 0.8169 - mse: 0.8169 - val_loss: 0.8355 - val_mse: 0.8355\n",
      "Epoch 3/5\n",
      "251312/251312 [==============================] - 41s 162us/sample - loss: 0.8149 - mse: 0.8149 - val_loss: 0.8391 - val_mse: 0.8391\n",
      "Epoch 4/5\n",
      "251312/251312 [==============================] - 41s 161us/sample - loss: 0.8125 - mse: 0.8125 - val_loss: 0.8411 - val_mse: 0.8411\n",
      "Epoch 5/5\n",
      "251312/251312 [==============================] - 36s 145us/sample - loss: 0.8109 - mse: 0.8109 - val_loss: 0.8386 - val_mse: 0.8386\n"
     ]
    }
   ],
   "source": [
    "model_leak.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(learning_rate=0.0003), metrics=[\"mse\"])\n",
    "history = model_leak.fit(X_train, y_train, validation_split=0.2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "955ea593",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:34:26.924618Z",
     "start_time": "2022-04-07T06:34:00.285255Z"
    }
   },
   "outputs": [],
   "source": [
    "index_col = df.drop([\"row_id\", \"target\", \"time_id\"], axis=1).columns\n",
    "X_train = df[index_col]\n",
    "X_train = X_train.astype(\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fdda2be8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:34:28.215732Z",
     "start_time": "2022-04-07T06:34:27.729640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>investment_id</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_290</th>\n",
       "      <th>f_291</th>\n",
       "      <th>f_292</th>\n",
       "      <th>f_293</th>\n",
       "      <th>f_294</th>\n",
       "      <th>f_295</th>\n",
       "      <th>f_296</th>\n",
       "      <th>f_297</th>\n",
       "      <th>f_298</th>\n",
       "      <th>f_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932617</td>\n",
       "      <td>0.113708</td>\n",
       "      <td>-0.402100</td>\n",
       "      <td>0.378418</td>\n",
       "      <td>-0.203979</td>\n",
       "      <td>-0.413574</td>\n",
       "      <td>0.965820</td>\n",
       "      <td>1.230469</td>\n",
       "      <td>0.114807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365967</td>\n",
       "      <td>-1.095703</td>\n",
       "      <td>0.200073</td>\n",
       "      <td>0.819336</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>-0.086792</td>\n",
       "      <td>-1.086914</td>\n",
       "      <td>-1.044922</td>\n",
       "      <td>-0.287598</td>\n",
       "      <td>0.321533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.811035</td>\n",
       "      <td>-0.514160</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>-0.616699</td>\n",
       "      <td>-0.194214</td>\n",
       "      <td>1.771484</td>\n",
       "      <td>1.427734</td>\n",
       "      <td>1.133789</td>\n",
       "      <td>0.114807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154175</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.819336</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>-0.387695</td>\n",
       "      <td>-1.086914</td>\n",
       "      <td>-0.929688</td>\n",
       "      <td>-0.974121</td>\n",
       "      <td>-0.343506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.394043</td>\n",
       "      <td>0.615723</td>\n",
       "      <td>0.567871</td>\n",
       "      <td>-0.607910</td>\n",
       "      <td>0.068909</td>\n",
       "      <td>-1.083008</td>\n",
       "      <td>0.979492</td>\n",
       "      <td>-1.125977</td>\n",
       "      <td>0.114807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138062</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>-0.551758</td>\n",
       "      <td>-1.220703</td>\n",
       "      <td>-1.060547</td>\n",
       "      <td>-0.219116</td>\n",
       "      <td>-1.086914</td>\n",
       "      <td>-0.612305</td>\n",
       "      <td>-0.113953</td>\n",
       "      <td>0.243652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-2.343750</td>\n",
       "      <td>-0.011871</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>-0.606445</td>\n",
       "      <td>-0.586914</td>\n",
       "      <td>-0.815918</td>\n",
       "      <td>0.778320</td>\n",
       "      <td>0.299072</td>\n",
       "      <td>0.114807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382080</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>-0.266357</td>\n",
       "      <td>-1.220703</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>-0.608887</td>\n",
       "      <td>0.104919</td>\n",
       "      <td>-0.783203</td>\n",
       "      <td>1.151367</td>\n",
       "      <td>-0.773438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.842285</td>\n",
       "      <td>-0.262939</td>\n",
       "      <td>2.330078</td>\n",
       "      <td>-0.583496</td>\n",
       "      <td>-0.618164</td>\n",
       "      <td>-0.742676</td>\n",
       "      <td>-0.946777</td>\n",
       "      <td>1.230469</td>\n",
       "      <td>0.114807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170410</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>-0.741211</td>\n",
       "      <td>-1.220703</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>-0.588379</td>\n",
       "      <td>0.104919</td>\n",
       "      <td>0.753418</td>\n",
       "      <td>1.345703</td>\n",
       "      <td>-0.737793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141405</th>\n",
       "      <td>3768.0</td>\n",
       "      <td>0.093506</td>\n",
       "      <td>-0.720215</td>\n",
       "      <td>-0.345459</td>\n",
       "      <td>-0.438721</td>\n",
       "      <td>-0.166992</td>\n",
       "      <td>-0.437256</td>\n",
       "      <td>1.475586</td>\n",
       "      <td>1.284180</td>\n",
       "      <td>0.056427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.285889</td>\n",
       "      <td>-1.232422</td>\n",
       "      <td>-0.660645</td>\n",
       "      <td>0.875488</td>\n",
       "      <td>0.421631</td>\n",
       "      <td>-0.427979</td>\n",
       "      <td>-0.075562</td>\n",
       "      <td>-0.533203</td>\n",
       "      <td>-0.193726</td>\n",
       "      <td>-0.581543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141406</th>\n",
       "      <td>3768.0</td>\n",
       "      <td>-1.344727</td>\n",
       "      <td>-0.199951</td>\n",
       "      <td>-0.107727</td>\n",
       "      <td>-0.454590</td>\n",
       "      <td>-0.221924</td>\n",
       "      <td>-0.141113</td>\n",
       "      <td>-1.498047</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>0.056427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184570</td>\n",
       "      <td>-1.232422</td>\n",
       "      <td>-0.670410</td>\n",
       "      <td>0.875488</td>\n",
       "      <td>0.421631</td>\n",
       "      <td>-0.729980</td>\n",
       "      <td>-1.514648</td>\n",
       "      <td>0.013145</td>\n",
       "      <td>-0.890137</td>\n",
       "      <td>-0.589844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141407</th>\n",
       "      <td>3770.0</td>\n",
       "      <td>0.979492</td>\n",
       "      <td>-1.110352</td>\n",
       "      <td>1.006836</td>\n",
       "      <td>-0.467285</td>\n",
       "      <td>-0.159546</td>\n",
       "      <td>1.355469</td>\n",
       "      <td>0.150757</td>\n",
       "      <td>-0.088928</td>\n",
       "      <td>0.056427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756348</td>\n",
       "      <td>-1.232422</td>\n",
       "      <td>0.820801</td>\n",
       "      <td>-1.142578</td>\n",
       "      <td>0.421631</td>\n",
       "      <td>-0.363281</td>\n",
       "      <td>1.363281</td>\n",
       "      <td>-0.079102</td>\n",
       "      <td>-1.580078</td>\n",
       "      <td>-0.297607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141408</th>\n",
       "      <td>3772.0</td>\n",
       "      <td>-2.564453</td>\n",
       "      <td>0.320312</td>\n",
       "      <td>0.076599</td>\n",
       "      <td>1.379883</td>\n",
       "      <td>-0.155396</td>\n",
       "      <td>-0.688965</td>\n",
       "      <td>0.381104</td>\n",
       "      <td>-1.325195</td>\n",
       "      <td>0.056427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756348</td>\n",
       "      <td>-1.232422</td>\n",
       "      <td>0.133057</td>\n",
       "      <td>-1.142578</td>\n",
       "      <td>0.421631</td>\n",
       "      <td>-0.375244</td>\n",
       "      <td>-1.514648</td>\n",
       "      <td>-0.973633</td>\n",
       "      <td>0.608887</td>\n",
       "      <td>-0.372070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141409</th>\n",
       "      <td>3772.0</td>\n",
       "      <td>-0.089539</td>\n",
       "      <td>0.190186</td>\n",
       "      <td>-0.548340</td>\n",
       "      <td>0.151245</td>\n",
       "      <td>0.079773</td>\n",
       "      <td>0.447998</td>\n",
       "      <td>1.014648</td>\n",
       "      <td>-1.325195</td>\n",
       "      <td>0.056427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.317139</td>\n",
       "      <td>0.811523</td>\n",
       "      <td>3.271484</td>\n",
       "      <td>0.875488</td>\n",
       "      <td>0.421631</td>\n",
       "      <td>-0.170654</td>\n",
       "      <td>1.363281</td>\n",
       "      <td>-0.563477</td>\n",
       "      <td>0.669434</td>\n",
       "      <td>0.456299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3141410 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         investment_id       f_0       f_1       f_2       f_3       f_4  \\\n",
       "0                  1.0  0.932617  0.113708 -0.402100  0.378418 -0.203979   \n",
       "1                  2.0  0.811035 -0.514160  0.742188 -0.616699 -0.194214   \n",
       "2                  6.0  0.394043  0.615723  0.567871 -0.607910  0.068909   \n",
       "3                  7.0 -2.343750 -0.011871  1.875000 -0.606445 -0.586914   \n",
       "4                  8.0  0.842285 -0.262939  2.330078 -0.583496 -0.618164   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "3141405         3768.0  0.093506 -0.720215 -0.345459 -0.438721 -0.166992   \n",
       "3141406         3768.0 -1.344727 -0.199951 -0.107727 -0.454590 -0.221924   \n",
       "3141407         3770.0  0.979492 -1.110352  1.006836 -0.467285 -0.159546   \n",
       "3141408         3772.0 -2.564453  0.320312  0.076599  1.379883 -0.155396   \n",
       "3141409         3772.0 -0.089539  0.190186 -0.548340  0.151245  0.079773   \n",
       "\n",
       "              f_5       f_6       f_7       f_8  ...     f_290     f_291  \\\n",
       "0       -0.413574  0.965820  1.230469  0.114807  ...  0.365967 -1.095703   \n",
       "1        1.771484  1.427734  1.133789  0.114807  ... -0.154175  0.912598   \n",
       "2       -1.083008  0.979492 -1.125977  0.114807  ... -0.138062  0.912598   \n",
       "3       -0.815918  0.778320  0.299072  0.114807  ...  0.382080  0.912598   \n",
       "4       -0.742676 -0.946777  1.230469  0.114807  ... -0.170410  0.912598   \n",
       "...           ...       ...       ...       ...  ...       ...       ...   \n",
       "3141405 -0.437256  1.475586  1.284180  0.056427  ... -0.285889 -1.232422   \n",
       "3141406 -0.141113 -1.498047  1.374023  0.056427  ...  0.184570 -1.232422   \n",
       "3141407  1.355469  0.150757 -0.088928  0.056427  ... -0.756348 -1.232422   \n",
       "3141408 -0.688965  0.381104 -1.325195  0.056427  ... -0.756348 -1.232422   \n",
       "3141409  0.447998  1.014648 -1.325195  0.056427  ... -0.317139  0.811523   \n",
       "\n",
       "            f_292     f_293     f_294     f_295     f_296     f_297     f_298  \\\n",
       "0        0.200073  0.819336  0.941406 -0.086792 -1.086914 -1.044922 -0.287598   \n",
       "1       -0.734375  0.819336  0.941406 -0.387695 -1.086914 -0.929688 -0.974121   \n",
       "2       -0.551758 -1.220703 -1.060547 -0.219116 -1.086914 -0.612305 -0.113953   \n",
       "3       -0.266357 -1.220703  0.941406 -0.608887  0.104919 -0.783203  1.151367   \n",
       "4       -0.741211 -1.220703  0.941406 -0.588379  0.104919  0.753418  1.345703   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "3141405 -0.660645  0.875488  0.421631 -0.427979 -0.075562 -0.533203 -0.193726   \n",
       "3141406 -0.670410  0.875488  0.421631 -0.729980 -1.514648  0.013145 -0.890137   \n",
       "3141407  0.820801 -1.142578  0.421631 -0.363281  1.363281 -0.079102 -1.580078   \n",
       "3141408  0.133057 -1.142578  0.421631 -0.375244 -1.514648 -0.973633  0.608887   \n",
       "3141409  3.271484  0.875488  0.421631 -0.170654  1.363281 -0.563477  0.669434   \n",
       "\n",
       "            f_299  \n",
       "0        0.321533  \n",
       "1       -0.343506  \n",
       "2        0.243652  \n",
       "3       -0.773438  \n",
       "4       -0.737793  \n",
       "...           ...  \n",
       "3141405 -0.581543  \n",
       "3141406 -0.589844  \n",
       "3141407 -0.297607  \n",
       "3141408 -0.372070  \n",
       "3141409  0.456299  \n",
       "\n",
       "[3141410 rows x 301 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "205a786b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:35:03.133658Z",
     "start_time": "2022-04-07T06:35:03.125679Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "904b86d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:34:32.999062Z",
     "start_time": "2022-04-07T06:34:32.876657Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(pd.DataFrame(df[\"investment_id\"]))\n",
    "X_train[\"investment_id\"] = scaler.transform(pd.DataFrame(X_train[\"investment_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d4b7a730",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:35:12.826424Z",
     "start_time": "2022-04-07T06:35:04.155694Z"
    }
   },
   "outputs": [],
   "source": [
    "X_valid, X_train, y_valid, y_train = train_test_split(X_train, y_train, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81506a87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T05:11:48.284627Z",
     "start_time": "2022-04-07T05:08:45.148087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 251312 samples, validate on 62829 samples\n",
      "Epoch 1/5\n",
      "251312/251312 [==============================] - 34s 136us/sample - loss: 0.8814 - mse: 0.8814 - val_loss: 0.8426 - val_mse: 0.8426\n",
      "Epoch 2/5\n",
      "251312/251312 [==============================] - 38s 152us/sample - loss: 0.8321 - mse: 0.8321 - val_loss: 0.8386 - val_mse: 0.8386\n",
      "Epoch 3/5\n",
      "251312/251312 [==============================] - 33s 132us/sample - loss: 0.8274 - mse: 0.8274 - val_loss: 0.8385 - val_mse: 0.8385\n",
      "Epoch 4/5\n",
      "251312/251312 [==============================] - 38s 150us/sample - loss: 0.8250 - mse: 0.8250 - val_loss: 0.8376 - val_mse: 0.8376\n",
      "Epoch 5/5\n",
      "251312/251312 [==============================] - 39s 156us/sample - loss: 0.8214 - mse: 0.8214 - val_loss: 0.8420 - val_mse: 0.8420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bd943eefd0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(learning_rate=0.0003), metrics=[\"mse\"])\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9bbf2706",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T05:15:11.595525Z",
     "start_time": "2022-04-07T05:11:48.810220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 251312 samples, validate on 62829 samples\n",
      "Epoch 1/5\n",
      "251312/251312 [==============================] - 41s 163us/sample - loss: 0.8531 - mse: 0.8531 - val_loss: 0.8420 - val_mse: 0.8420\n",
      "Epoch 2/5\n",
      "251312/251312 [==============================] - 39s 156us/sample - loss: 0.8311 - mse: 0.8311 - val_loss: 0.8385 - val_mse: 0.8385\n",
      "Epoch 3/5\n",
      "251312/251312 [==============================] - 41s 162us/sample - loss: 0.8282 - mse: 0.8282 - val_loss: 0.8416 - val_mse: 0.8416\n",
      "Epoch 4/5\n",
      "251312/251312 [==============================] - 40s 161us/sample - loss: 0.8255 - mse: 0.8255 - val_loss: 0.8369 - val_mse: 0.8369\n",
      "Epoch 5/5\n",
      "251312/251312 [==============================] - 41s 165us/sample - loss: 0.8240 - mse: 0.8240 - val_loss: 0.8380 - val_mse: 0.8380\n"
     ]
    }
   ],
   "source": [
    "model_leak.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(learning_rate=0.0003), metrics=[\"mse\"])\n",
    "history = model_leak.fit(X_train, y_train, validation_split=0.2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "05969400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T05:27:50.378196Z",
     "start_time": "2022-04-07T05:27:50.182844Z"
    }
   },
   "outputs": [],
   "source": [
    "Input = keras.layers.Input(shape=X_train.shape[1:])\n",
    "x = keras.layers.Conv1D(32, kernel_size=7, activation=\"relu\")(Input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Conv1D(64, kernel_size=5,  activation=\"relu\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Conv1D(128, kernel_size=5,  activation=\"relu\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Conv1D(256, kernel_size=3,  activation=\"relu\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "Output = keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "model = keras.models.Model(inputs = Input, outputs = Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4b2fa03f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T05:37:18.963164Z",
     "start_time": "2022-04-07T05:27:50.862893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 251312 samples, validate on 62829 samples\n",
      "Epoch 1/5\n",
      "251312/251312 [==============================] - 116s 461us/sample - loss: 2.3230 - mse: 2.3230 - val_loss: 1.2339 - val_mse: 1.2339\n",
      "Epoch 2/5\n",
      "251312/251312 [==============================] - 112s 448us/sample - loss: 0.8916 - mse: 0.8916 - val_loss: 0.8427 - val_mse: 0.8427\n",
      "Epoch 3/5\n",
      "251312/251312 [==============================] - 113s 450us/sample - loss: 0.8268 - mse: 0.8268 - val_loss: 0.8395 - val_mse: 0.8395\n",
      "Epoch 4/5\n",
      "251312/251312 [==============================] - 114s 453us/sample - loss: 0.8214 - mse: 0.8214 - val_loss: 0.8390 - val_mse: 0.8390\n",
      "Epoch 5/5\n",
      "251312/251312 [==============================] - 113s 448us/sample - loss: 0.8118 - mse: 0.8118 - val_loss: 0.8453 - val_mse: 0.8453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bd9a079c88>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(learning_rate=0.0003), metrics=[\"mse\"])\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d18f6622",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T05:50:01.951470Z",
     "start_time": "2022-04-07T05:50:01.694444Z"
    }
   },
   "outputs": [],
   "source": [
    "Input = keras.layers.Input(shape=X_train.shape[1:])\n",
    "x = keras.layers.Conv1D(32, kernel_size=7, activation=\"relu\")(Input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Conv1D(64, kernel_size=5,  activation=\"relu\")(x)\n",
    "x = keras.layers.GRU(30)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "Output = keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "model = keras.models.Model(inputs = Input, outputs = Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "20cef8a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T05:58:45.642673Z",
     "start_time": "2022-04-07T05:50:02.375332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 251312 samples, validate on 62829 samples\n",
      "Epoch 1/5\n",
      "251312/251312 [==============================] - 107s 426us/sample - loss: 0.8478 - mse: 0.8478 - val_loss: 0.8490 - val_mse: 0.8490\n",
      "Epoch 2/5\n",
      "251312/251312 [==============================] - 105s 420us/sample - loss: 0.8403 - mse: 0.8403 - val_loss: 0.8477 - val_mse: 0.8477\n",
      "Epoch 3/5\n",
      "251312/251312 [==============================] - 104s 414us/sample - loss: 0.8383 - mse: 0.8383 - val_loss: 0.8477 - val_mse: 0.8477\n",
      "Epoch 4/5\n",
      "251312/251312 [==============================] - 103s 411us/sample - loss: 0.8368 - mse: 0.8368 - val_loss: 0.8476 - val_mse: 0.8476\n",
      "Epoch 5/5\n",
      "251312/251312 [==============================] - 103s 410us/sample - loss: 0.8355 - mse: 0.8355 - val_loss: 0.8462 - val_mse: 0.8462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1beb8c5c358>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(learning_rate=0.0003), metrics=[\"mse\"])\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7dd3e9f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T05:58:46.272112Z",
     "start_time": "2022-04-07T05:58:46.072618Z"
    }
   },
   "outputs": [],
   "source": [
    "Input = keras.layers.Input(shape=X_train.shape[1:])\n",
    "x = keras.layers.GRU(30)(Input)\n",
    "Output = keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "model = keras.models.Model(inputs = Input, outputs = Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2ec5231f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:07:36.433767Z",
     "start_time": "2022-04-07T05:58:46.683719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 251312 samples, validate on 62829 samples\n",
      "Epoch 1/5\n",
      "251312/251312 [==============================] - 106s 423us/sample - loss: 0.8416 - mse: 0.8416 - val_loss: 0.8506 - val_mse: 0.8506\n",
      "Epoch 2/5\n",
      "251312/251312 [==============================] - 106s 421us/sample - loss: 0.8403 - mse: 0.8403 - val_loss: 0.8492 - val_mse: 0.8492\n",
      "Epoch 3/5\n",
      "251312/251312 [==============================] - 107s 428us/sample - loss: 0.8388 - mse: 0.8388 - val_loss: 0.8517 - val_mse: 0.8517\n",
      "Epoch 4/5\n",
      "251312/251312 [==============================] - 106s 421us/sample - loss: 0.8383 - mse: 0.8383 - val_loss: 0.8481 - val_mse: 0.8481\n",
      "Epoch 5/5\n",
      "251312/251312 [==============================] - 104s 414us/sample - loss: 0.8380 - mse: 0.8380 - val_loss: 0.8474 - val_mse: 0.8474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bfac30e048>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(learning_rate=0.0003), metrics=[\"mse\"])\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1238c804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:42:32.498429Z",
     "start_time": "2022-04-07T06:42:32.311695Z"
    }
   },
   "outputs": [],
   "source": [
    "Input = keras.layers.Input(shape=X_train.shape[1])\n",
    "x = keras.layers.Dense(128)(Input)\n",
    "x = keras.layers.PReLU()(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(64)(x)\n",
    "x = keras.layers.PReLU()(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(32)(x)\n",
    "x = keras.layers.PReLU()(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(16)(x)\n",
    "x = keras.layers.PReLU()(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "Output = keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "model = keras.models.Model(inputs = Input, outputs = Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f187f684",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:45:38.193975Z",
     "start_time": "2022-04-07T06:42:32.908861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 251312 samples, validate on 62829 samples\n",
      "Epoch 1/5\n",
      "251312/251312 [==============================] - 38s 152us/sample - loss: 0.8639 - mse: 0.8639 - val_loss: 0.8403 - val_mse: 0.8403\n",
      "Epoch 2/5\n",
      "251312/251312 [==============================] - 37s 147us/sample - loss: 0.8360 - mse: 0.8360 - val_loss: 0.8315 - val_mse: 0.8315\n",
      "Epoch 3/5\n",
      "251312/251312 [==============================] - 35s 141us/sample - loss: 0.8314 - mse: 0.8314 - val_loss: 0.8317 - val_mse: 0.8317\n",
      "Epoch 4/5\n",
      "251312/251312 [==============================] - 38s 150us/sample - loss: 0.8274 - mse: 0.8274 - val_loss: 0.8291 - val_mse: 0.8291\n",
      "Epoch 5/5\n",
      "251312/251312 [==============================] - 37s 146us/sample - loss: 0.8237 - mse: 0.8237 - val_loss: 0.8357 - val_mse: 0.8357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bfab46ffd0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e650d03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T05:25:09.312880Z",
     "start_time": "2022-04-07T05:25:09.294929Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d6bd623",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T05:24:46.024857Z",
     "start_time": "2022-04-07T05:24:45.907138Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42972886",
   "metadata": {
    "papermill": {
     "duration": 11.551319,
     "end_time": "2022-03-30T14:06:33.781957",
     "exception": false,
     "start_time": "2022-03-30T14:06:22.230638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f9d36e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T14:06:55.803323Z",
     "iopub.status.busy": "2022-03-30T14:06:55.802662Z",
     "iopub.status.idle": "2022-03-30T14:06:56.287773Z",
     "shell.execute_reply": "2022-03-30T14:06:56.288474Z",
     "shell.execute_reply.started": "2022-03-30T12:24:31.994612Z"
    },
    "papermill": {
     "duration": 11.496034,
     "end_time": "2022-03-30T14:06:56.288633",
     "exception": false,
     "start_time": "2022-03-30T14:06:44.792599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "import ubiquant\n",
    "model = tf.keras.models.load_model('model.h5')\n",
    "env = ubiquant.make_env()   \n",
    "iter_test = env.iter_test()    \n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    sample_prediction_df[\"target\"] = model.predict(test_df[index_col].astype(\"float16\"))\n",
    "    env.predict(sample_prediction_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6.8",
   "language": "python",
   "name": "python3.6.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2134.664216,
   "end_time": "2022-03-30T14:07:10.868727",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-30T13:31:36.204511",
   "version": "2.3.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "907.778px",
    "left": "68.9931px",
    "top": "180.002px",
    "width": "426.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "595.851px",
    "left": "1764.33px",
    "right": "20px",
    "top": "121px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
